{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio import warp\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "\n",
    "def crop_geotiff(input_tiff_path, output_dir, crop_width, crop_height, output_geotiff):\n",
    "    # Open the large GeoTIFF image\n",
    "    ds = gdal.Open(input_tiff_path)\n",
    "    gt = ds.GetGeoTransform()\n",
    "    projection = ds.GetProjection()\n",
    "    band = ds.GetRasterBand(1)\n",
    "    No_data = band.GetNoDataValue()\n",
    "    arr = np.array(band.ReadAsArray())\n",
    "    print('Array', np.max(arr), np.min(arr), No_data)\n",
    "    \n",
    "    ds_LC = gdal.Open(output_geotiff)\n",
    "    band_LC = ds_LC.GetRasterBand(1)\n",
    "    arr_LC = np.array(band_LC.ReadAsArray())\n",
    "    \n",
    "    arr=np.where(arr_LC == 11, 0.0, arr) #arr[arr_LC==11] = 0.0\n",
    "    # Create a new raster file to save the modified band\n",
    "    output_tiff_path = os.path.join(output_dir,'target_no_waterbody.tif')\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    out_ds = driver.Create(\n",
    "        output_tiff_path,\n",
    "        ds.RasterXSize,\n",
    "        ds.RasterYSize,\n",
    "        1,  # Number of bands\n",
    "        gdal.GDT_Float32,  # Data type\n",
    "    )\n",
    "\n",
    "    # Set the GeoTransform and Projection for the output file\n",
    "    out_ds.SetGeoTransform(gt)\n",
    "    out_ds.SetProjection(projection)\n",
    "\n",
    "    # Write the modified data to the new file\n",
    "    out_band = out_ds.GetRasterBand(1)\n",
    "    out_band.WriteArray(arr)\n",
    "    # print(np.sum(arr))\n",
    "    out_band.SetNoDataValue(No_data)\n",
    "    \n",
    "    ds = gdal.Open(output_tiff_path)\n",
    "    gt = ds.GetGeoTransform()\n",
    "    projection = ds.GetProjection()\n",
    "    band = ds.GetRasterBand(1)\n",
    "    \n",
    "    arr=np.where(arr == No_data, np.nan, arr) #arr[arr==No_data ] = np.nan\n",
    "    print('Array', np.max(arr), np.min(arr), No_data)\n",
    "    img_width = ds.RasterXSize\n",
    "    img_height = ds.RasterYSize\n",
    "\n",
    "    # Calculate number of tiles in x and y directions\n",
    "    x_tiles = img_width // crop_width\n",
    "    y_tiles = img_height // crop_height\n",
    "    count = 1\n",
    "    for i in range(x_tiles):\n",
    "        for j in range(y_tiles):\n",
    "            # Calculate pixel coordinates for the tile\n",
    "            offset_x = i * crop_width\n",
    "            offset_y = j * crop_height\n",
    "            \n",
    "            # Read the data for the tile\n",
    "            tile_data = band.ReadAsArray(offset_x, offset_y, crop_width, crop_height)\n",
    "            tile_data=np.where(tile_data == No_data, np.nan, tile_data)\n",
    "            \n",
    "            \n",
    "            # if np.sum(np.isnan(tile_data))>0.0 or np.sum(tile_data)==0.0: #(np.sum(tile_data)/(crop_width*crop_height))<0.00001\n",
    "            #     # print(np.sum(tile_data)/(crop_width*crop_height))\n",
    "            #     # print(np.max(tile_data))\n",
    "            #     continue\n",
    "            # else:\n",
    "            if np.sum(tile_data)>0.0:\n",
    "                print(np.max(tile_data), np.min(tile_data))\n",
    "\n",
    "            \n",
    "                # Create the cropped output file\n",
    "                driver = gdal.GetDriverByName('GTiff')\n",
    "                output_file = os.path.join(output_dir, raster_path.split(\"/\")[-1][:-4]+f'_crop_{count}.tif')\n",
    "                out_ds = driver.Create(output_file, crop_width, crop_height, 1, band.DataType)\n",
    "                \n",
    "                # Set GeoTransform and Projection for the cropped file\n",
    "                new_gt = (\n",
    "                    gt[0] + offset_x * gt[1], gt[1], gt[2],\n",
    "                    gt[3] + offset_y * gt[5], gt[4], gt[5]\n",
    "                )\n",
    "                out_ds.SetGeoTransform(new_gt)\n",
    "                out_ds.SetProjection(ds.GetProjection())\n",
    "                \n",
    "                \n",
    "                # Write the cropped data to the output file\n",
    "                out_ds.GetRasterBand(1).WriteArray(tile_data)\n",
    "                # out_ds.SetNoDataValue(No_data)\n",
    "                out_ds.FlushCache()\n",
    "                \n",
    "                # Clean up\n",
    "                out_ds = None\n",
    "                count += 1\n",
    "\n",
    "crop_width = 512                       # Width of each cropped image (in pixels)\n",
    "crop_height = 512  \n",
    "\n",
    "# Input files and directories\n",
    "events_file = '/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "combined_df = pd.read_csv(events_file, header=None)\n",
    "\n",
    "for idx, raster_path in enumerate(combined_df[0]): \n",
    "    event = raster_path.split(\"/\")[-1][:-4]  # Extract event name from raster path\n",
    "    TARGET_RASTER_DIR = f\"/p/lustre1/lazin1/RAPID_Archive_Flood_Maps/Tile_No_waterbody/{event}\"\n",
    "    \n",
    "    if os.path.exists(TARGET_RASTER_DIR):\n",
    "        print('Exists', TARGET_RASTER_DIR)\n",
    "        # continue\n",
    "    else:\n",
    "        print('New', TARGET_RASTER_DIR)\n",
    "        os.makedirs(TARGET_RASTER_DIR, exist_ok=True)\n",
    "\n",
    "    # Output directory for cropped raster\n",
    "    cropped_output_dir = TARGET_RASTER_DIR\n",
    "    temp_raster_path = f\"/p/lustre2/lazin1/Annual_NLCD_LndCov_2023_CU_C1V0.tif\"\n",
    "    output_geotiff = os.path.join(cropped_output_dir, 'LC_' + event + '.tif')\n",
    "    reference_raster = raster_path\n",
    "\n",
    "    # Process the reference raster\n",
    "    with rasterio.open(reference_raster) as ref:\n",
    "        ref_transform = ref.transform\n",
    "        ref_crs = ref.crs\n",
    "        ref_shape = (ref.height, ref.width)\n",
    "        ref_bounds = ref.bounds\n",
    "        ref_nodata = ref.nodata  # Get NoData value from reference raster\n",
    "\n",
    "    # Reproject and resample to match the reference raster\n",
    "    with rasterio.open(temp_raster_path) as src:\n",
    "        with rasterio.open(\n",
    "            output_geotiff,\n",
    "            \"w\",\n",
    "            driver=\"GTiff\",\n",
    "            height=ref_shape[0],\n",
    "            width=ref_shape[1],\n",
    "            count=1,\n",
    "            dtype=\"float32\",\n",
    "            crs=ref_crs,\n",
    "            transform=ref_transform,\n",
    "            nodata=ref_nodata  # Use the same NoData value as the reference raster\n",
    "        ) as dst:\n",
    "            # Create an array for the destination\n",
    "            destination_array = np.empty((ref_shape[0], ref_shape[1]), dtype=\"float32\")\n",
    "            destination_array.fill(ref_nodata)  # Initialize with NoData value\n",
    "            \n",
    "\n",
    "            # Reproject the data\n",
    "            warp.reproject(\n",
    "                source=rasterio.band(src, 1),\n",
    "                destination=destination_array,\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=ref_transform,\n",
    "                dst_crs=ref_crs,\n",
    "                resampling=warp.Resampling.nearest\n",
    "            )\n",
    "\n",
    "            # Mask with NoData where reference has NoData\n",
    "            with rasterio.open(reference_raster) as ref:\n",
    "                reference_data = ref.read(1)  # Read reference raster band\n",
    "                destination_array[reference_data == ref_nodata] = ref_nodata  # Apply NoData mask\n",
    "                # destination_array[destination_array == 11] = ref_nodata\n",
    "\n",
    "            # Write to the output raster\n",
    "            dst.write(destination_array, 1)\n",
    "\n",
    "\n",
    "    print(f\"Processed and saved: {output_geotiff}\")\n",
    "    try:\n",
    "        print(f\"Processing {raster_path}...\")\n",
    "        crop_geotiff(raster_path, TARGET_RASTER_DIR, crop_width, crop_height, output_geotiff)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    os.remove(output_geotiff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio import warp\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "file = '/p/lustre1/lazin1/RAPID_Archive_Flood_Maps/Tile_No_waterbody/flood_WM_S1A_IW_GRDH_1SDV_20180919T231415_20180919T231440_023774_0297CC_374E/target_no_waterbody.tif'\n",
    "\n",
    "ds = gdal.Open(file)\n",
    "gt = ds.GetGeoTransform()\n",
    "projection = ds.GetProjection()\n",
    "band = ds.GetRasterBand(1)\n",
    "array = band.ReadAsArray()\n",
    "print(np.nanmax(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# Define the GeoTIFF file path\n",
    "geotiff_path = f\"/p/lustre1/lazin1/RAPID_Archive_Flood_Maps/Tile_No_waterbody/flood_WM_S1A_IW_GRDH_1SDV_20180919T231415_20180919T231440_023774_0297CC_374E/target_no_waterbody.tif\"\n",
    "\n",
    "# Open the GeoTIFF\n",
    "with rasterio.open(geotiff_path) as src:\n",
    "    # Read the first band as a NumPy array (assuming single-band raster)\n",
    "    raster_array = src.read(1)\n",
    "\n",
    "    # Get raster dimensions\n",
    "    rows, cols = raster_array.shape\n",
    "\n",
    "    # Define the patch size\n",
    "    patch_size = 512\n",
    "\n",
    "    # Initialize variables to track the maximum sum and patch coordinates\n",
    "    max_sum = -np.inf\n",
    "    max_coords = (0, 0)  # Top-left corner of the maximum-sum patch\n",
    "\n",
    "    # Iterate over the raster using a sliding window of size 512x512\n",
    "    for i in range(0, rows - patch_size + 1):\n",
    "        for j in range(0, cols - patch_size + 1):\n",
    "            # Extract the patch\n",
    "            patch = raster_array[i:i + patch_size, j:j + patch_size]\n",
    "\n",
    "            # Calculate the sum of the patch\n",
    "            patch_sum = np.sum(patch)\n",
    "\n",
    "            # Update the maximum sum and coordinates if a new maximum is found\n",
    "            if patch_sum > max_sum:\n",
    "                max_sum = patch_sum\n",
    "                max_coords = (i, j)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Maximum sum: {max_sum}\")\n",
    "    print(f\"Top-left corner of the maximum-sum patch: Row={max_coords[0]}, Col={max_coords[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0 , 1 , np.nan])\n",
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def crop_geotiff(input_tiff_path, output_dir, crop_width, crop_height):\n",
    "    # Open the large GeoTIFF image\n",
    "    ds = gdal.Open(input_tiff_path)\n",
    "    gt = ds.GetGeoTransform()\n",
    "    band = ds.GetRasterBand(1)\n",
    "    No_data = band.GetNoDataValue()\n",
    "    arr = np.array(band.ReadAsArray())\n",
    "    # print('Array', np.max(arr), np.min(arr), No_data)\n",
    "    img_width = ds.RasterXSize\n",
    "    img_height = ds.RasterYSize\n",
    "\n",
    "    # Calculate number of tiles in x and y directions\n",
    "    x_tiles = img_width // crop_width\n",
    "    y_tiles = img_height // crop_height\n",
    "    count = 1\n",
    "    for i in range(x_tiles):\n",
    "        for j in range(y_tiles):\n",
    "            # Calculate pixel coordinates for the tile\n",
    "            offset_x = i * crop_width\n",
    "            offset_y = j * crop_height\n",
    "            \n",
    "            # Read the data for the tile\n",
    "            tile_data = band.ReadAsArray(offset_x, offset_y, crop_width, crop_height)\n",
    "            tile_data=np.where(tile_data == No_data, np.nan, tile_data)\n",
    "            \n",
    "            if np.sum(np.isnan(tile_data))>0:\n",
    "                continue\n",
    "            else:\n",
    "                # print(np.max(tile_data), np.min(tile_data))\n",
    "\n",
    "            \n",
    "                # Create the cropped output file\n",
    "                driver = gdal.GetDriverByName('GTiff')\n",
    "                output_file = os.path.join(output_dir, raster_path.split(\"/\")[-1][:-4]+f'_crop_{count}.tif')\n",
    "                out_ds = driver.Create(output_file, crop_width, crop_height, 1, band.DataType)\n",
    "                \n",
    "                # Set GeoTransform and Projection for the cropped file\n",
    "                new_gt = (\n",
    "                    gt[0] + offset_x * gt[1], gt[1], gt[2],\n",
    "                    gt[3] + offset_y * gt[5], gt[4], gt[5]\n",
    "                )\n",
    "                out_ds.SetGeoTransform(new_gt)\n",
    "                out_ds.SetProjection(ds.GetProjection())\n",
    "                \n",
    "                \n",
    "                # Write the cropped data to the output file\n",
    "                out_ds.GetRasterBand(1).WriteArray(tile_data)\n",
    "                # out_ds.SetNoDataValue(No_data)\n",
    "                out_ds.FlushCache()\n",
    "                \n",
    "                # Clean up\n",
    "                out_ds = None\n",
    "                count += 1\n",
    "\n",
    "# Parameters\n",
    "# input_tiff_path = '/p/lustre1/lazin1/RAPID_Archive_Flood_Maps/20170829/flooding_S1A_IW_GRDH_1SDV_20170829T002620_20170829T002645_018131_01E74D_D734/flood_WM_S1A_IW_GRDH_1SDV_20170829T002620_20170829T002645_018131_01E74D_D734.tif'  # Path to the large GeoTIFF image\n",
    "           # Folder to save cropped images\n",
    "crop_width = 512                       # Width of each cropped image (in pixels)\n",
    "crop_height = 512                     # Height of each cropped image (in pixels)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "# EVENT_STR = \"Harvey_20170829_D734_non_flood\"\n",
    "# EVENT_STRS = [\"Harvey_20170829_D734_non_flood\",\"Harvey_20170831_9366_non_flood\" , \"Harvey_20170831_0776_non_flood\", \"Harvey_20170829_B8C4_non_flood\", \"Harvey_20170829_3220_non_flood\"]\n",
    "\n",
    "# EVENT_STRS = [\"Harvey_20170829_D734_non_flood\",\"Harvey_20170831_9366_non_flood\" , \"Harvey_20170831_0776_non_flood\", \"Harvey_20170829_B8C4_non_flood\", \"Harvey_20170829_3220_non_flood\"]\n",
    "# EVENT_STRS = [\"Florence_20180919_374E_non_flood\", \"Florence_20180919_B86C_non_flood\"]\n",
    "\n",
    "####### WHEN EVENT_Mississippi_3AC6_non_flood.csv type file is privided\n",
    "\n",
    "# EVENT_STRS= [\"All\"]\n",
    "\n",
    "\n",
    "\n",
    "# # Harvey_20170829_3220_non_flood.csv #Harvey_20170829_B8C4_non_flood.csv  #Harvey_20170831_0776_non_flood.csv #Harvey_20170831_9366_non_flood.csv #Harvey_20170829_D734_non_flood.csv\n",
    "# #\"Mississippi_20190617_B9D7_non_flood\" #\"Mississippi_20190617_B9D7_non_flood\"  # \"Mississippi_20190617_42BF_non_flood\"  #\"Mississippi_20190617_3AC6_non_flood\" #\"Mississippi_20190617_9D85_non_flood\" #\"Mississippi_20190617_5E5F_non_flood\"\n",
    "# for EVENT_STR in EVENT_STRS:\n",
    "#     RASTER_PATHS = pd.read_csv(f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENT_{EVENT_STR}.csv\", header=None) #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/flood_img_list_flood_non_flood_test2.csv')  #/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENT_MISSISSIPPI_non_flood_20190617_3AC6.csv #/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENT_MISSISSIPPI_non_flood_20190617_C310.csv  #/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENT_MISSISSIPPI_non_flood_20190617_B9D7.csv\n",
    "#     # print(RASTER_PATHS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Harvey_20170829_3220_non_flood.csv #Harvey_20170829_B8C4_non_flood.csv  #Harvey_20170831_0776_non_flood.csv #Harvey_20170831_9366_non_flood.csv #Harvey_20170829_D734_non_flood.csv\n",
    "\n",
    "# #\"Mississippi_20190617_B9D7_non_flood\" #\"Mississippi_20190617_B9D7_non_flood\"  # \"Mississippi_20190617_42BF_non_flood\"  #\"Mississippi_20190617_3AC6_non_flood\" #\"Mississippi_20190617_9D85_non_flood\" #\"Mississippi_20190617_5E5F_non_flood\"\n",
    "\n",
    "\n",
    "# # RASTER_PATHS = pd.read_csv(f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENT_{EVENT_STR}.csv\"), header=None) #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/flood_img_list_flood_non_flood_test2.csv')  #/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENT_MISSISSIPPI_non_flood_20190617_3AC6.csv #/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENT_MISSISSIPPI_non_flood_20190617_C310.csv  #/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENT_MISSISSIPPI_non_flood_20190617_B9D7.csv\n",
    "\n",
    "#     raster_paths= RASTER_PATHS.to_numpy()\n",
    "\n",
    "#     for idx, raster_path in enumerate(raster_paths):\n",
    "#         output_dir = f\"/p/lustre1/lazin1/RAPID_Archive_Flood_Maps/Tile_No_Threshold_{EVENT_STR}\"\n",
    "#         os.makedirs(output_dir, exist_ok=True)\n",
    "#         try:\n",
    "#             print(f\"Processing {raster_path[0]}...\")\n",
    "#             crop_geotiff(raster_path[0], output_dir, crop_width, crop_height)\n",
    "#         except:\n",
    "#             continue\n",
    "        \n",
    "        \n",
    "  ####### WHEN EVENT_Mississippi_3AC6_non_flood.csv type file is privided      \n",
    "        \n",
    "events_file = '/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "combined_df = pd.read_csv(events_file, header=None) \n",
    "for idx, raster_path in enumerate(combined_df[0]): #events = [raster_path.split(\"/\")[-1][:-4] \n",
    "    # print(raster_path)\n",
    "    dir = raster_path.split(\"/\")[-1][:-4]\n",
    "    output_dir = f\"/p/lustre1/lazin1/RAPID_Archive_Flood_Maps/Tile_{dir}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    try:\n",
    "        print(f\"Processing {raster_path}...\")\n",
    "        crop_geotiff(raster_path, output_dir, crop_width, crop_height)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "# Define the GeoTIFF file path\n",
    "geotiff_path = \"input.tif\"\n",
    "\n",
    "# Open the GeoTIFF\n",
    "with rasterio.open(geotiff_path) as src:\n",
    "    # Read the first band as a NumPy array (assuming single-band raster)\n",
    "    raster_array = src.read(1)\n",
    "\n",
    "    # Get raster dimensions\n",
    "    rows, cols = raster_array.shape\n",
    "\n",
    "    # Define the patch size\n",
    "    patch_size = 512\n",
    "\n",
    "    # Initialize variables to track the maximum sum and patch coordinates\n",
    "    max_sum = -np.inf\n",
    "    max_coords = (0, 0)  # Top-left corner of the maximum-sum patch\n",
    "\n",
    "    # Iterate over the raster using a sliding window of size 512x512\n",
    "    for i in range(0, rows - patch_size + 1):\n",
    "        for j in range(0, cols - patch_size + 1):\n",
    "            # Extract the patch\n",
    "            patch = raster_array[i:i + patch_size, j:j + patch_size]\n",
    "\n",
    "            # Calculate the sum of the patch\n",
    "            patch_sum = np.sum(patch)\n",
    "\n",
    "            # Update the maximum sum and coordinates if a new maximum is found\n",
    "            if patch_sum > max_sum:\n",
    "                max_sum = patch_sum\n",
    "                max_coords = (i, j)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Maximum sum: {max_sum}\")\n",
    "    print(f\"Top-left corner of the maximum-sum patch: Row={max_coords[0]}, Col={max_coords[1]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPID",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
