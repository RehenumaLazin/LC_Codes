{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49639902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Flood Model Training Notebook\n",
    "# Includes: Synthetic data generation, patching, training loop with MSE loss, checkpointing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------\n",
    "# Model Components (from previous response)\n",
    "# -------------------------\n",
    "class GlobalEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=64):\n",
    "        super(GlobalEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(64, out_channels, 3, stride=2, padding=1), nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class LocalUNet(nn.Module):\n",
    "    def __init__(self, in_channels=4, global_channels=64):\n",
    "        super(LocalUNet, self).__init__()\n",
    "        input_channels = in_channels + global_channels\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.final_conv = nn.Conv2d(64, 1, 1)\n",
    "\n",
    "    def forward(self, x_local, global_context):\n",
    "        global_upsampled = nn.functional.interpolate(global_context, size=x_local.shape[2:], mode='bilinear')\n",
    "        x = torch.cat([x_local, global_upsampled], dim=1)\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.pool(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.up1(x3)\n",
    "        x5 = torch.relu(x1 + x4)\n",
    "        return self.final_conv(x5)\n",
    "\n",
    "class HybridFloodModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridFloodModel, self).__init__()\n",
    "        self.global_encoder = GlobalEncoder(in_channels=4)\n",
    "        self.local_unet = LocalUNet(in_channels=4, global_channels=64)\n",
    "\n",
    "    def forward(self, global_input, local_patch):\n",
    "        global_context = self.global_encoder(global_input)\n",
    "        return self.local_unet(local_patch, global_context)\n",
    "\n",
    "# -------------------------\n",
    "# Synthetic Dataset\n",
    "# -------------------------\n",
    "class SyntheticFloodDataset(Dataset):\n",
    "    def __init__(self, n_samples=200):\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        global_input = torch.rand(4, 64, 64)  # coarse input\n",
    "        local_patch = torch.rand(4, 256, 256) # hi-res patch\n",
    "        target = torch.rand(1, 256, 256)      # flood depth\n",
    "        return global_input, local_patch, target\n",
    "\n",
    "# -------------------------\n",
    "# Training Setup\n",
    "# -------------------------\n",
    "def save_checkpoint(model, optimizer, epoch, loss, path=\"checkpoint.pt\"):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }, path)\n",
    "\n",
    "def load_checkpoint(model, optimizer, path=\"checkpoint.pt\"):\n",
    "    if os.path.exists(path):\n",
    "        checkpoint = torch.load(path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}.\")\n",
    "        return start_epoch\n",
    "    else:\n",
    "        print(\"No checkpoint found, starting from scratch.\")\n",
    "        return 0\n",
    "\n",
    "# -------------------------\n",
    "# Training Loop\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridFloodModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "dataset = SyntheticFloodDataset(n_samples=200)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "num_epochs = 50\n",
    "start_epoch = load_checkpoint(model, optimizer)\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for global_input, local_patch, target in tqdm(dataloader):\n",
    "        global_input = global_input.to(device)\n",
    "        local_patch = local_patch.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(global_input, local_patch)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "    save_checkpoint(model, optimizer, epoch, loss.item())\n",
    "    torch.save(model.state_dict(), f\"model_epoch_{epoch+1}.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyproj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
