{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file):\n",
    "    \"\"\"\n",
    "    Compute the mean and standard deviation for each pixel across multiple GeoTIFF files and save as numpy arrays.\n",
    "\n",
    "    Args:\n",
    "        geotiff_files (list of str): List of GeoTIFF file paths.\n",
    "        output_mean_file (str): Path to save the mean numpy array.\n",
    "        output_std_file (str): Path to save the standard deviation numpy array.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize variables for incremental computation\n",
    "    mean_accumulator = None\n",
    "    squared_sum_accumulator = None\n",
    "    count_accumulator = None\n",
    "\n",
    "    for idx, geotiff_path in enumerate(geotiff_files):\n",
    "        try:\n",
    "            # Open GeoTIFF and read the array\n",
    "            with rasterio.open(geotiff_path) as src:\n",
    "                array = src.read(1)  # Read the first band\n",
    "                array = array.astype(np.float64)  # Ensure precision for computation\n",
    "\n",
    "                # Initialize accumulators on the first iteration\n",
    "                if mean_accumulator is None:\n",
    "                    mean_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    squared_sum_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    count_accumulator = np.zeros_like(array, dtype=np.int64)\n",
    "\n",
    "                # Update accumulators (ignore NaN values)\n",
    "                valid_mask = ~np.isnan(array)\n",
    "                mean_accumulator[valid_mask] += array[valid_mask]\n",
    "                squared_sum_accumulator[valid_mask] += array[valid_mask] ** 2\n",
    "                count_accumulator[valid_mask] += 1\n",
    "\n",
    "            # Print progress every 1,000 files\n",
    "            if (idx + 1) % 1000 == 0:\n",
    "                print(f\"Processed {idx + 1}/{len(geotiff_files)} files...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {geotiff_path}: {e}\")\n",
    "\n",
    "    # Compute mean and standard deviation\n",
    "    pixelwise_mean = mean_accumulator / count_accumulator\n",
    "    pixelwise_variance = (squared_sum_accumulator / count_accumulator) - (pixelwise_mean ** 2)\n",
    "    pixelwise_std_dev = np.sqrt(pixelwise_variance)\n",
    "\n",
    "    # Save mean and standard deviation as numpy arrays\n",
    "    np.save(output_mean_file, pixelwise_mean)\n",
    "    np.save(output_std_file, pixelwise_std_dev)\n",
    "\n",
    "    print(f\"Pixelwise mean saved to {output_mean_file}\")\n",
    "    print(f\"Pixelwise standard deviation saved to {output_std_file}\")\n",
    "\n",
    "\n",
    "    # events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "    # tiles_df = pd.read_csv(events_file)\n",
    "    # tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "TARGET_RASTER_DIR = f\"/p/lustre1/lazin1/RAPID_Archive_Flood_Maps/Tile_Sonoma/\" \n",
    "tile_names = sorted(glob.glob(f\"{TARGET_RASTER_DIR}/*.tif\"))\n",
    "\n",
    "\n",
    "DEM = []\n",
    "LC = []\n",
    "day1_prec = []\n",
    "day5_prec = []\n",
    "streamflow = []\n",
    "SM = []\n",
    "label_geotiff_path = []\n",
    "for tile_name in tile_names:\n",
    "    tile_str = tile_name.split(\"case\")[-1]#tile_name.split(\"crop\")[0][:-1] \n",
    "    event = tile_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "    date = tile_name.split(\"/\")[-1].split(\"_\")[1]\n",
    "    \n",
    "    DEM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_DEM/Sonoma/case{tile_str}\")\n",
    "    LC.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_LC/Sonoma/LC_case{tile_str}\")\n",
    "    day1_prec.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/1D_prec/Sonoma/{event}/1day_prec_{tile_name}\")\n",
    "    day5_prec.append( f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/5D_prec/Sonoma/{event}/5day_prec_{tile_name}\")\n",
    "    streamflow.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/streamflow/Sonoma/{event}/streamflow_{tile_name}\")\n",
    "    SM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_SM/Sonoma/{event}/SM_{tile_name}\")\n",
    "    \n",
    "    label_geotiff_path.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/WM/Tile_Sonoma/{event}/{tile_name}\") \n",
    "    \n",
    "    \n",
    "# GeoTIFF paths\n",
    "\n",
    "input_geotiff_paths =[\n",
    "DEM,\n",
    "LC,\n",
    "day1_prec,\n",
    "day5_prec,\n",
    "streamflow,\n",
    "SM\n",
    "]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "geotiff_files = DEM  # Replace with actual paths\n",
    "output_mean_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/DEM_Sonoma_mean.npy\"\n",
    "output_std_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/DEM_Sonoma_std_dev.npy\"\n",
    "\n",
    "compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/3031 files...\n",
      "Processed 2000/3031 files...\n",
      "Processed 3000/3031 files...\n",
      "Pixelwise mean saved to /p/vast1/lazin1/UNet_inputs/mean_stds/day1_prec_Sonoma_mean.npy\n",
      "Pixelwise standard deviation saved to /p/vast1/lazin1/UNet_inputs/mean_stds/day1_prec_Sonoma_std_dev.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file):\n",
    "    \"\"\"\n",
    "    Compute the mean and standard deviation for each pixel across multiple GeoTIFF files and save as numpy arrays.\n",
    "\n",
    "    Args:\n",
    "        geotiff_files (list of str): List of GeoTIFF file paths.\n",
    "        output_mean_file (str): Path to save the mean numpy array.\n",
    "        output_std_file (str): Path to save the standard deviation numpy array.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize variables for incremental computation\n",
    "    mean_accumulator = None\n",
    "    squared_sum_accumulator = None\n",
    "    count_accumulator = None\n",
    "\n",
    "    for idx, geotiff_path in enumerate(geotiff_files):\n",
    "        try:\n",
    "            # Open GeoTIFF and read the array\n",
    "            with rasterio.open(geotiff_path) as src:\n",
    "                array = src.read(1)  # Read the first band\n",
    "                array = array.astype(np.float64)  # Ensure precision for computation\n",
    "\n",
    "                # Initialize accumulators on the first iteration\n",
    "                if mean_accumulator is None:\n",
    "                    mean_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    squared_sum_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    count_accumulator = np.zeros_like(array, dtype=np.int64)\n",
    "\n",
    "                # Update accumulators (ignore NaN values)\n",
    "                valid_mask = ~np.isnan(array)\n",
    "                mean_accumulator[valid_mask] += array[valid_mask]\n",
    "                squared_sum_accumulator[valid_mask] += array[valid_mask] ** 2\n",
    "                count_accumulator[valid_mask] += 1\n",
    "\n",
    "            # Print progress every 1,000 files\n",
    "            if (idx + 1) % 1000 == 0:\n",
    "                print(f\"Processed {idx + 1}/{len(geotiff_files)} files...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {geotiff_path}: {e}\")\n",
    "\n",
    "    # Compute mean and standard deviation\n",
    "    pixelwise_mean = mean_accumulator / count_accumulator\n",
    "    pixelwise_variance = (squared_sum_accumulator / count_accumulator) - (pixelwise_mean ** 2)\n",
    "    pixelwise_std_dev = np.sqrt(pixelwise_variance)\n",
    "\n",
    "    # Save mean and standard deviation as numpy arrays\n",
    "    np.save(output_mean_file, pixelwise_mean)\n",
    "    np.save(output_std_file, pixelwise_std_dev)\n",
    "\n",
    "    print(f\"Pixelwise mean saved to {output_mean_file}\")\n",
    "    print(f\"Pixelwise standard deviation saved to {output_std_file}\")\n",
    "\n",
    "\n",
    "    # events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "    # tiles_df = pd.read_csv(events_file)\n",
    "    # tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "tiles_df = pd.read_csv(events_file)\n",
    "tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "\n",
    "\n",
    "DEM = []\n",
    "LC = []\n",
    "day1_prec = []\n",
    "day5_prec = []\n",
    "streamflow = []\n",
    "SM = []\n",
    "label_geotiff_path = []\n",
    "for tile_name in tile_names:\n",
    "    tile_str = tile_name.split(\"case\")[-1]#tile_name.split(\"crop\")[0][:-1] \n",
    "    event = tile_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "    date = tile_name.split(\"/\")[-1].split(\"_\")[1]\n",
    "    \n",
    "    DEM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_DEM/Sonoma/case{tile_str}\")\n",
    "    LC.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_LC/Sonoma/LC_case{tile_str}\")\n",
    "    day1_prec.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/1D_prec/Sonoma/{event}/1day_prec_{tile_name}\")\n",
    "    day5_prec.append( f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/5D_prec/Sonoma/{event}/5day_prec_{tile_name}\")\n",
    "    streamflow.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/streamflow/Sonoma/{event}/streamflow_{tile_name}\")\n",
    "    SM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_SM/Sonoma/{event}/SM_{tile_name}\")\n",
    "    \n",
    "    label_geotiff_path.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/WM/Tile_Sonoma/{event}/{tile_name}\") \n",
    "    \n",
    "    \n",
    "# GeoTIFF paths\n",
    "\n",
    "input_geotiff_paths =[\n",
    "DEM,\n",
    "LC,\n",
    "day1_prec,\n",
    "day5_prec,\n",
    "streamflow,\n",
    "SM\n",
    "]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "geotiff_files = day1_prec  # Replace with actual paths\n",
    "output_mean_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/day1_prec_Sonoma_mean.npy\"\n",
    "output_std_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/day1_prec_Sonoma_std_dev.npy\"\n",
    "\n",
    "compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 D prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/3031 files...\n",
      "Processed 2000/3031 files...\n",
      "Processed 3000/3031 files...\n",
      "Pixelwise mean saved to /p/vast1/lazin1/UNet_inputs/mean_stds/day5_prec_Sonoma_mean.npy\n",
      "Pixelwise standard deviation saved to /p/vast1/lazin1/UNet_inputs/mean_stds/day5_prec_Sonoma_std_dev.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file):\n",
    "    \"\"\"\n",
    "    Compute the mean and standard deviation for each pixel across multiple GeoTIFF files and save as numpy arrays.\n",
    "\n",
    "    Args:\n",
    "        geotiff_files (list of str): List of GeoTIFF file paths.\n",
    "        output_mean_file (str): Path to save the mean numpy array.\n",
    "        output_std_file (str): Path to save the standard deviation numpy array.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize variables for incremental computation\n",
    "    mean_accumulator = None\n",
    "    squared_sum_accumulator = None\n",
    "    count_accumulator = None\n",
    "\n",
    "    for idx, geotiff_path in enumerate(geotiff_files):\n",
    "        try:\n",
    "            # Open GeoTIFF and read the array\n",
    "            with rasterio.open(geotiff_path) as src:\n",
    "                array = src.read(1)  # Read the first band\n",
    "                array = array.astype(np.float64)  # Ensure precision for computation\n",
    "\n",
    "                # Initialize accumulators on the first iteration\n",
    "                if mean_accumulator is None:\n",
    "                    mean_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    squared_sum_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    count_accumulator = np.zeros_like(array, dtype=np.int64)\n",
    "\n",
    "                # Update accumulators (ignore NaN values)\n",
    "                valid_mask = ~np.isnan(array)\n",
    "                mean_accumulator[valid_mask] += array[valid_mask]\n",
    "                squared_sum_accumulator[valid_mask] += array[valid_mask] ** 2\n",
    "                count_accumulator[valid_mask] += 1\n",
    "\n",
    "            # Print progress every 1,000 files\n",
    "            if (idx + 1) % 1000 == 0:\n",
    "                print(f\"Processed {idx + 1}/{len(geotiff_files)} files...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {geotiff_path}: {e}\")\n",
    "\n",
    "    # Compute mean and standard deviation\n",
    "    pixelwise_mean = mean_accumulator / count_accumulator\n",
    "    pixelwise_variance = (squared_sum_accumulator / count_accumulator) - (pixelwise_mean ** 2)\n",
    "    pixelwise_std_dev = np.sqrt(pixelwise_variance)\n",
    "\n",
    "    # Save mean and standard deviation as numpy arrays\n",
    "    np.save(output_mean_file, pixelwise_mean)\n",
    "    np.save(output_std_file, pixelwise_std_dev)\n",
    "\n",
    "    print(f\"Pixelwise mean saved to {output_mean_file}\")\n",
    "    print(f\"Pixelwise standard deviation saved to {output_std_file}\")\n",
    "\n",
    "\n",
    "    # events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "    # tiles_df = pd.read_csv(events_file)\n",
    "    # tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "tiles_df = pd.read_csv(events_file)\n",
    "tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "\n",
    "\n",
    "DEM = []\n",
    "LC = []\n",
    "day1_prec = []\n",
    "day5_prec = []\n",
    "streamflow = []\n",
    "SM = []\n",
    "label_geotiff_path = []\n",
    "for tile_name in tile_names:\n",
    "    tile_str = tile_name.split(\"case\")[-1]#tile_name.split(\"crop\")[0][:-1] \n",
    "    event = tile_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "    date = tile_name.split(\"/\")[-1].split(\"_\")[1]\n",
    "    \n",
    "    DEM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_DEM/Sonoma/case{tile_str}\")\n",
    "    LC.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_LC/Sonoma/LC_case{tile_str}\")\n",
    "    day1_prec.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/1D_prec/Sonoma/{event}/1day_prec_{tile_name}\")\n",
    "    day5_prec.append( f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/5D_prec/Sonoma/{event}/5day_prec_{tile_name}\")\n",
    "    streamflow.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/streamflow/Sonoma/{event}/streamflow_{tile_name}\")\n",
    "    SM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_SM/Sonoma/{event}/SM_{tile_name}\")\n",
    "    \n",
    "    label_geotiff_path.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/WM/Tile_Sonoma/{event}/{tile_name}\") \n",
    "    \n",
    "    \n",
    "# GeoTIFF paths\n",
    "\n",
    "input_geotiff_paths =[\n",
    "DEM,\n",
    "LC,\n",
    "day1_prec,\n",
    "day5_prec,\n",
    "streamflow,\n",
    "SM\n",
    "]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "geotiff_files = day5_prec  # Replace with actual paths\n",
    "output_mean_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/day5_prec_Sonoma_mean.npy\"\n",
    "output_std_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/day5_prec_Sonoma_std_dev.npy\"\n",
    "\n",
    "compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/3031 files...\n",
      "Processed 2000/3031 files...\n",
      "Processed 3000/3031 files...\n",
      "Pixelwise mean saved to /p/vast1/lazin1/UNet_inputs/mean_stds/Streamflow_Sonoma_mean.npy\n",
      "Pixelwise standard deviation saved to /p/vast1/lazin1/UNet_inputs/mean_stds/Streamflow_Sonoma_std_dev.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file):\n",
    "    \"\"\"\n",
    "    Compute the mean and standard deviation for each pixel across multiple GeoTIFF files and save as numpy arrays.\n",
    "\n",
    "    Args:\n",
    "        geotiff_files (list of str): List of GeoTIFF file paths.\n",
    "        output_mean_file (str): Path to save the mean numpy array.\n",
    "        output_std_file (str): Path to save the standard deviation numpy array.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize variables for incremental computation\n",
    "    mean_accumulator = None\n",
    "    squared_sum_accumulator = None\n",
    "    count_accumulator = None\n",
    "\n",
    "    for idx, geotiff_path in enumerate(geotiff_files):\n",
    "        try:\n",
    "            # Open GeoTIFF and read the array\n",
    "            with rasterio.open(geotiff_path) as src:\n",
    "                array = src.read(1)  # Read the first band\n",
    "                array = array.astype(np.float64)  # Ensure precision for computation\n",
    "\n",
    "                # Initialize accumulators on the first iteration\n",
    "                if mean_accumulator is None:\n",
    "                    mean_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    squared_sum_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    count_accumulator = np.zeros_like(array, dtype=np.int64)\n",
    "\n",
    "                # Update accumulators (ignore NaN values)\n",
    "                valid_mask = ~np.isnan(array)\n",
    "                mean_accumulator[valid_mask] += array[valid_mask]\n",
    "                squared_sum_accumulator[valid_mask] += array[valid_mask] ** 2\n",
    "                count_accumulator[valid_mask] += 1\n",
    "\n",
    "            # Print progress every 1,000 files\n",
    "            if (idx + 1) % 1000 == 0:\n",
    "                print(f\"Processed {idx + 1}/{len(geotiff_files)} files...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {geotiff_path}: {e}\")\n",
    "\n",
    "    # Compute mean and standard deviation\n",
    "    pixelwise_mean = mean_accumulator / count_accumulator\n",
    "    pixelwise_variance = (squared_sum_accumulator / count_accumulator) - (pixelwise_mean ** 2)\n",
    "    pixelwise_std_dev = np.sqrt(pixelwise_variance)\n",
    "\n",
    "    # Save mean and standard deviation as numpy arrays\n",
    "    np.save(output_mean_file, pixelwise_mean)\n",
    "    np.save(output_std_file, pixelwise_std_dev)\n",
    "\n",
    "    print(f\"Pixelwise mean saved to {output_mean_file}\")\n",
    "    print(f\"Pixelwise standard deviation saved to {output_std_file}\")\n",
    "\n",
    "\n",
    "    # events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "    # tiles_df = pd.read_csv(events_file)\n",
    "    # tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "tiles_df = pd.read_csv(events_file)\n",
    "tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "\n",
    "\n",
    "DEM = []\n",
    "LC = []\n",
    "day1_prec = []\n",
    "day5_prec = []\n",
    "streamflow = []\n",
    "SM = []\n",
    "label_geotiff_path = []\n",
    "for tile_name in tile_names:\n",
    "    tile_str = tile_name.split(\"case\")[-1]#tile_name.split(\"crop\")[0][:-1] \n",
    "    event = tile_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "    date = tile_name.split(\"/\")[-1].split(\"_\")[1]\n",
    "    \n",
    "    DEM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_DEM/Sonoma/case{tile_str}\")\n",
    "    LC.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_LC/Sonoma/LC_case{tile_str}\")\n",
    "    day1_prec.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/1D_prec/Sonoma/{event}/1day_prec_{tile_name}\")\n",
    "    day5_prec.append( f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/5D_prec/Sonoma/{event}/5day_prec_{tile_name}\")\n",
    "    streamflow.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/streamflow/Sonoma/{event}/streamflow_{tile_name}\")\n",
    "    SM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_SM/Sonoma/{event}/SM_{tile_name}\")\n",
    "    \n",
    "    label_geotiff_path.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/WM/Tile_Sonoma/{event}/{tile_name}\") \n",
    "    \n",
    "    \n",
    "# GeoTIFF paths\n",
    "\n",
    "input_geotiff_paths =[\n",
    "DEM,\n",
    "LC,\n",
    "day1_prec,\n",
    "day5_prec,\n",
    "streamflow,\n",
    "SM\n",
    "]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "geotiff_files = streamflow  # Replace with actual paths\n",
    "output_mean_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/Streamflow_Sonoma_mean.npy\"\n",
    "output_std_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/Streamflow_Sonoma_std_dev.npy\"\n",
    "\n",
    "compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/3031 files...\n",
      "Processed 2000/3031 files...\n",
      "Processed 3000/3031 files...\n",
      "Pixelwise mean saved to /p/vast1/lazin1/UNet_inputs/mean_stds/SM_Sonoma_mean.npy\n",
      "Pixelwise standard deviation saved to /p/vast1/lazin1/UNet_inputs/mean_stds/SM_Sonoma_std_dev.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file):\n",
    "    \"\"\"\n",
    "    Compute the mean and standard deviation for each pixel across multiple GeoTIFF files and save as numpy arrays.\n",
    "\n",
    "    Args:\n",
    "        geotiff_files (list of str): List of GeoTIFF file paths.\n",
    "        output_mean_file (str): Path to save the mean numpy array.\n",
    "        output_std_file (str): Path to save the standard deviation numpy array.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize variables for incremental computation\n",
    "    mean_accumulator = None\n",
    "    squared_sum_accumulator = None\n",
    "    count_accumulator = None\n",
    "\n",
    "    for idx, geotiff_path in enumerate(geotiff_files):\n",
    "        try:\n",
    "            # Open GeoTIFF and read the array\n",
    "            with rasterio.open(geotiff_path) as src:\n",
    "                array = src.read(1)  # Read the first band\n",
    "                array = array.astype(np.float64)  # Ensure precision for computation\n",
    "\n",
    "                # Initialize accumulators on the first iteration\n",
    "                if mean_accumulator is None:\n",
    "                    mean_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    squared_sum_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    count_accumulator = np.zeros_like(array, dtype=np.int64)\n",
    "\n",
    "                # Update accumulators (ignore NaN values)\n",
    "                valid_mask = ~np.isnan(array)\n",
    "                mean_accumulator[valid_mask] += array[valid_mask]\n",
    "                squared_sum_accumulator[valid_mask] += array[valid_mask] ** 2\n",
    "                count_accumulator[valid_mask] += 1\n",
    "\n",
    "            # Print progress every 1,000 files\n",
    "            if (idx + 1) % 1000 == 0:\n",
    "                print(f\"Processed {idx + 1}/{len(geotiff_files)} files...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {geotiff_path}: {e}\")\n",
    "\n",
    "    # Compute mean and standard deviation\n",
    "    pixelwise_mean = mean_accumulator / count_accumulator\n",
    "    pixelwise_variance = (squared_sum_accumulator / count_accumulator) - (pixelwise_mean ** 2)\n",
    "    pixelwise_std_dev = np.sqrt(pixelwise_variance)\n",
    "\n",
    "    # Save mean and standard deviation as numpy arrays\n",
    "    np.save(output_mean_file, pixelwise_mean)\n",
    "    np.save(output_std_file, pixelwise_std_dev)\n",
    "\n",
    "    print(f\"Pixelwise mean saved to {output_mean_file}\")\n",
    "    print(f\"Pixelwise standard deviation saved to {output_std_file}\")\n",
    "\n",
    "\n",
    "    # events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "    # tiles_df = pd.read_csv(events_file)\n",
    "    # tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "tiles_df = pd.read_csv(events_file)\n",
    "tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "\n",
    "\n",
    "DEM = []\n",
    "LC = []\n",
    "day1_prec = []\n",
    "day5_prec = []\n",
    "streamflow = []\n",
    "SM = []\n",
    "label_geotiff_path = []\n",
    "for tile_name in tile_names:\n",
    "    tile_str = tile_name.split(\"case\")[-1]#tile_name.split(\"crop\")[0][:-1] \n",
    "    event = tile_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "    date = tile_name.split(\"/\")[-1].split(\"_\")[1]\n",
    "    \n",
    "    DEM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_DEM/Sonoma/case{tile_str}\")\n",
    "    LC.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_LC/Sonoma/LC_case{tile_str}\")\n",
    "    day1_prec.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/1D_prec/Sonoma/{event}/1day_prec_{tile_name}\")\n",
    "    day5_prec.append( f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/5D_prec/Sonoma/{event}/5day_prec_{tile_name}\")\n",
    "    streamflow.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/streamflow/Sonoma/{event}/streamflow_{tile_name}\")\n",
    "    SM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_SM/Sonoma/{event}/SM_{tile_name}\")\n",
    "    \n",
    "    label_geotiff_path.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/WM/Tile_Sonoma/{event}/{tile_name}\") \n",
    "    \n",
    "    \n",
    "# GeoTIFF paths\n",
    "\n",
    "input_geotiff_paths =[\n",
    "DEM,\n",
    "LC,\n",
    "day1_prec,\n",
    "day5_prec,\n",
    "streamflow,\n",
    "SM\n",
    "]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "geotiff_files = SM  # Replace with actual paths\n",
    "output_mean_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/SM_Sonoma_mean.npy\"\n",
    "output_std_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/SM_Sonoma_std_dev.npy\"\n",
    "\n",
    "compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000/3031 files...\n",
      "Processed 2000/3031 files...\n",
      "Processed 3000/3031 files...\n",
      "Pixelwise mean saved to /p/vast1/lazin1/UNet_inputs/mean_stds/Flood_depth_Sonoma_mean.npy\n",
      "Pixelwise standard deviation saved to /p/vast1/lazin1/UNet_inputs/mean_stds/Flood_depth_Sonoma_std_dev.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file):\n",
    "    \"\"\"\n",
    "    Compute the mean and standard deviation for each pixel across multiple GeoTIFF files and save as numpy arrays.\n",
    "\n",
    "    Args:\n",
    "        geotiff_files (list of str): List of GeoTIFF file paths.\n",
    "        output_mean_file (str): Path to save the mean numpy array.\n",
    "        output_std_file (str): Path to save the standard deviation numpy array.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize variables for incremental computation\n",
    "    mean_accumulator = None\n",
    "    squared_sum_accumulator = None\n",
    "    count_accumulator = None\n",
    "\n",
    "    for idx, geotiff_path in enumerate(geotiff_files):\n",
    "        try:\n",
    "            # Open GeoTIFF and read the array\n",
    "            with rasterio.open(geotiff_path) as src:\n",
    "                array = src.read(1)  # Read the first band\n",
    "                array = array.astype(np.float64)  # Ensure precision for computation\n",
    "\n",
    "                # Initialize accumulators on the first iteration\n",
    "                if mean_accumulator is None:\n",
    "                    mean_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    squared_sum_accumulator = np.zeros_like(array, dtype=np.float64)\n",
    "                    count_accumulator = np.zeros_like(array, dtype=np.int64)\n",
    "\n",
    "                # Update accumulators (ignore NaN values)\n",
    "                valid_mask = ~np.isnan(array)\n",
    "                mean_accumulator[valid_mask] += array[valid_mask]\n",
    "                squared_sum_accumulator[valid_mask] += array[valid_mask] ** 2\n",
    "                count_accumulator[valid_mask] += 1\n",
    "\n",
    "            # Print progress every 1,000 files\n",
    "            if (idx + 1) % 1000 == 0:\n",
    "                print(f\"Processed {idx + 1}/{len(geotiff_files)} files...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {geotiff_path}: {e}\")\n",
    "\n",
    "    # Compute mean and standard deviation\n",
    "    pixelwise_mean = mean_accumulator / count_accumulator\n",
    "    pixelwise_variance = (squared_sum_accumulator / count_accumulator) - (pixelwise_mean ** 2)\n",
    "    pixelwise_std_dev = np.sqrt(pixelwise_variance)\n",
    "\n",
    "    # Save mean and standard deviation as numpy arrays\n",
    "    np.save(output_mean_file, pixelwise_mean)\n",
    "    np.save(output_std_file, pixelwise_std_dev)\n",
    "\n",
    "    print(f\"Pixelwise mean saved to {output_mean_file}\")\n",
    "    print(f\"Pixelwise standard deviation saved to {output_std_file}\")\n",
    "\n",
    "\n",
    "    # events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "    # tiles_df = pd.read_csv(events_file)\n",
    "    # tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "events_file = f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/Sonoma_shapefile/Tile_Sonoma.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined_{EVENT_STR}_No_Threshold.csv\" #f\"/usr/workspace/lazin1/anaconda_dane/envs/RAPID/Codes/combined.csv\"  #'/usr/workspace/lazin1/anaconda_dane/envs/RAPID/EVENTS/combined.csv'\n",
    "\n",
    "tiles_df = pd.read_csv(events_file)\n",
    "tile_names = tiles_df['ras_name'].tolist()  # Assuming the column is named 'tile_name'\n",
    "\n",
    "\n",
    "DEM = []\n",
    "LC = []\n",
    "day1_prec = []\n",
    "day5_prec = []\n",
    "streamflow = []\n",
    "SM = []\n",
    "label_geotiff_path = []\n",
    "for tile_name in tile_names:\n",
    "    tile_str = tile_name.split(\"case\")[-1]#tile_name.split(\"crop\")[0][:-1] \n",
    "    event = tile_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "    date = tile_name.split(\"/\")[-1].split(\"_\")[1]\n",
    "    \n",
    "    DEM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_DEM/Sonoma/case{tile_str}\")\n",
    "    LC.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_LC/Sonoma/LC_case{tile_str}\")\n",
    "    day1_prec.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/1D_prec/Sonoma/{event}/1day_prec_{tile_name}\")\n",
    "    day5_prec.append( f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/5D_prec/Sonoma/{event}/5day_prec_{tile_name}\")\n",
    "    streamflow.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/streamflow/Sonoma/{event}/streamflow_{tile_name}\")\n",
    "    SM.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/cropped_SM/Sonoma/{event}/SM_{tile_name}\")\n",
    "    \n",
    "    label_geotiff_path.append(f\"/p/vast1/lazin1/UNet_inputs/Geotiff_var/WM/Tile_Sonoma/{event}/{tile_name}\") \n",
    "    \n",
    "    \n",
    "# GeoTIFF paths\n",
    "\n",
    "input_geotiff_paths =[\n",
    "DEM,\n",
    "LC,\n",
    "day1_prec,\n",
    "day5_prec,\n",
    "streamflow,\n",
    "SM\n",
    "]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "geotiff_files = label_geotiff_path  # Replace with actual paths\n",
    "output_mean_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/Flood_depth_Sonoma_mean.npy\"\n",
    "output_std_file = f\"/p/vast1/lazin1/UNet_inputs/mean_stds/Flood_depth_Sonoma_std_dev.npy\"\n",
    "\n",
    "compute_pixelwise_mean_std(geotiff_files, output_mean_file, output_std_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyproj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
